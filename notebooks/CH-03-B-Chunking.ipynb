{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reto 03-B-Chunking (Segmentación)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Descripción General \n",
    "\n",
    "En este notebook, repasarás los conceptos de tokens y chunking. En el notebook anterior (`CH-03-A-Grounding`), pudimos proporcionar algo de contexto adicional para fundamentar el modelo. ¿Existe un límite para la cantidad de contexto adicional que podemos proporcionar al modelo? Desafortunadamente, la respuesta es sí. Existe un límite para la cantidad de tokens permitidos en la entrada y la salida combinadas según el modelo que se esté utilizando.\n",
    "\n",
    "Entonces, ¿qué son los tokens? Los tokens son una representación de cómo los modelos de Azure OpenAI procesan el texto. Son palabras o simplemente fragmentos de caracteres. Veamos el número total de tokens en la respuesta que obtuvimos del primer notebook del Desafío 3. Hay muchas formas de calcular tokens. En este notebook, echaremos un vistazo a la biblioteca `tiktoken` para contar los tokens."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Comencemos con la Implementación\n",
    "\n",
    "Necesitarás importar los módulos necesarios. Las siguientes celdas son pasos de configuración de claves que ya completaste en los desafíos anteriores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: click in /usr/local/python/3.12.1/lib/python3.12/site-packages (8.1.7)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n",
      "Collecting en-core-web-sm==3.7.1\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.7.1/en_core_web_sm-3.7.1-py3-none-any.whl (12.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m53.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.2 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from en-core-web-sm==3.7.1) (3.7.5)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.10)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.8)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.2.5)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.1.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.4.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.4.1)\n",
      "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.13.1)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.67.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /home/codespace/.local/lib/python3.12/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.32.3)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.9.2)\n",
      "Requirement already satisfied: jinja2 in /home/codespace/.local/lib/python3.12/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.1.4)\n",
      "Requirement already satisfied: setuptools in /home/codespace/.local/lib/python3.12/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (75.1.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/codespace/.local/lib/python3.12/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (24.1)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.5.0)\n",
      "Requirement already satisfied: numpy>=1.19.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.26.4)\n",
      "Requirement already satisfied: language-data>=1.2 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.3.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.23.4)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /home/codespace/.local/lib/python3.12/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.9.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/codespace/.local/lib/python3.12/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/codespace/.local/lib/python3.12/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/codespace/.local/lib/python3.12/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/codespace/.local/lib/python3.12/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2024.8.30)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.5)\n",
      "Requirement already satisfied: click>=8.0.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.1.7)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (13.9.4)\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.20.0)\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (7.0.5)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/codespace/.local/lib/python3.12/site-packages (from jinja2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.1.5)\n",
      "Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.2.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/codespace/.local/lib/python3.12/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.18.0)\n",
      "Requirement already satisfied: wrapt in /usr/local/python/3.12.1/lib/python3.12/site-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.16.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.2)\n",
      "Installing collected packages: en-core-web-sm\n",
      "Successfully installed en-core-web-sm-3.7.1\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "! pip install --upgrade click\n",
    "! python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import PyPDF3\n",
    "import os\n",
    "import json\n",
    "import tiktoken\n",
    "import spacy\n",
    "from openai.error import InvalidRequestError\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "load_dotenv(find_dotenv())\n",
    "\n",
    "from spacy.lang.en import English \n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "import langchain\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configura tu entorno para acceder a tus claves de Azure OpenAI. Consulta tu recurso de Azure OpenAI en el Portal de Azure para obtener información sobre tu punto de conexión y claves de Azure OpenAI.\n",
    "\n",
    "Por razones de seguridad, almacena tu información sensible en un archivo .env."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your OpenAI credentials\n",
    "API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "assert API_KEY, \"ERROR: Azure OpenAI Key is missing\"\n",
    "openai.api_key = API_KEY\n",
    "\n",
    "RESOURCE_ENDPOINT = os.getenv(\"OPENAI_API_BASE\",\"\").strip()\n",
    "assert RESOURCE_ENDPOINT, \"ERROR: Azure OpenAI Endpoint is missing\"\n",
    "assert \"openai.azure.com\" in RESOURCE_ENDPOINT.lower(), \"ERROR: Azure OpenAI Endpoint should be in the form: \\n\\n\\t<your unique endpoint identifier>.openai.azure.com\"\n",
    "openai.api_base = RESOURCE_ENDPOINT\n",
    "\n",
    "openai.api_type = os.getenv(\"OPENAI_API_TYPE\")\n",
    "openai.api_version = os.getenv(\"OPENAI_API_VERSION\")\n",
    "model=os.getenv(\"CHAT_MODEL_NAME\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Conteo de Tokens\n",
    "\n",
    "`tiktoken` utiliza una técnica llamada codificación de pares de bytes (BPE) para convertir el texto dado en tokens. Hay diferentes codificaciones disponibles para ayudar a procesar las palabras. En este norebook, utilizaremos `cl100k_base`.\n",
    "\n",
    "#### Tarea #1 del Estudiante: \n",
    "\n",
    "Cuenta el número de tokens en la respuesta final que recibimos en `CH-03-A-Grounding` completando la función `count_tokens` a continuación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def count_tokens(string: str, encoding_name: str) -> int:\n",
    "    # Escribe el código aquí\n",
    "    return "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tarea #2 del Estudiante:\n",
    "\n",
    "Ingresa el texto de la respuesta que recibiste en `CH-03-A-Grounding`. Ejecuta la celda a continuación para recuperar el número de tokens utilizando la función `count_tokens`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"Ganadores:\n",
    "- Carlos Alcaraz en individuales masculinos\n",
    "- Markéta Vondroušová en individuales femeninos\n",
    "\n",
    "Perdedores:\n",
    "- Novak Djokovic en individuales masculinos\n",
    "- Ons Jabeur en individuales femeninos\"\"\"\n",
    "\n",
    "count_tokens(text, \"cl100k_base\")\n",
    "\n",
    "print(\"There are \" + str(count_tokens(text, \"cl100k_base\")) + \" tokens: \" + text)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Muy bien, ahora sabemos con cuántos tokens estamos trabajando. ¿Qué sucede si queremos agregar más contexto que el que ya pusimos en la variable de texto anterior? Si pensamos en nuestro escenario de Wimbledon, necesitaremos darle al modelo más contexto para ayudarlo a entender todo lo que necesita saber sobre el torneo. Más importante aún, todo lo que necesita saber para ayudar a responder tus preguntas al escribir el informe. Digamos que queremos proporcionar más contexto al modelo con un documento PDF. ¿Podemos intentar obtener un resumen del documento PDF para ayudarnos con nuestro trabajo?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tarea #3 del Estudiante:\n",
    "\n",
    "En la celda siguiente, inserta la ruta del documento PDF, `CH3-data.pdf`, que se encuentra en la carpeta `/data` proporcionada. Ejecuta las tres celdas para ver la salida."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "document = open(r'Insert PDF file path', 'rb') \n",
    "doc_helper = PyPDF3.PdfFileReader(document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finaltext = ''\n",
    "totalpages = doc_helper.getNumPages()\n",
    "for eachpage in range(totalpages):\n",
    "   p = doc_helper.getPage(eachpage)\n",
    "   indpagetext = p.extractText()\n",
    "   finaltext += indpagetext\n",
    "\n",
    "clean_text = finaltext.replace(\"  \", \" \").replace(\"\\n\", \"; \").replace(';',' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f\"What is the answer to the following question regarding the PDF document?\\n\\n{finaltext}\\n\\n\" \n",
    "q = \"Can you give me a summary of the document?\"\n",
    "\n",
    "try:\n",
    "    final_prompt = prompt + q\n",
    "    response = openai.ChatCompletion.create(engine=model, messages=final_prompt, max_tokens=50)\n",
    "    answer = response.choices[0].text.strip()\n",
    "    print(f\"{q}\\n{answer}\\n\")\n",
    "\n",
    "except InvalidRequestError as e:\n",
    "    print(e.error)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como has podido observar, recibiste un mensaje de error después de ejecutar el fragmento de código anterior. El modelo alcanza su longitud de contexto máxima. Para los modelos GPT-3, el límite de tokens es de 4097 tokens. ¿Cómo solucionamos este problema al proporcionarle todo el contexto necesario, pero sin encontrarnos con el problema del límite de tokens?\n",
    "\n",
    "Para resolver este problema, podemos echar un vistazo a un concepto llamado Chunking (Segmentación)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Chunking (Segmentación)\n",
    "\n",
    "La segmentación ayuda a limitar la cantidad de información que pasamos al modelo. La información que pasaremos son los trozos más relevantes de los datos en general. Hay muchas consideraciones que entran en juego al hacer segmentación. Por ejemplo, necesitas averiguar el mejor tamaño de chunk (trozo). Si los trozos son demasiado pequeños, puedes perder contexto importante. Si los trozos son demasiado grandes, pueden contener información innecesaria.\n",
    "\n",
    "A continuación se presentan algunas técnicas comunes de chunking.\n",
    "\n",
    "1. Chunking con trozos más pequeños\n",
    "2. Chunking dividiendo las oraciones\n",
    "3. Chunking con superposición de oraciones\n",
    "4. Chunking de forma recursiva\n",
    "\n",
    "Veamos estas técnicas en acción."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Chunking con trozos más pequeños\n",
    "\n",
    "#### Tarea #4 del Estudiante: \n",
    "\n",
    "Agrega código en la celda siguiente. Utiliza la función `split()` para dividir el texto en trozos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "text = \"The sun was setting over the horizon, casting a warm glow over the landscape. Birds chirped in the trees, and a gentle breeze rustled the leaves. In the distance, a herd of deer grazed in a meadow. The air was filled with the sweet scent of blooming flowers. It was a peaceful and serene scene, perfect for a quiet evening stroll.\"\n",
    "\n",
    "# Agrega tu código aquí"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿Qué puedes observar sobre los trozos devueltos? Si vieras cada trozo de manera individual, ¿podrías entender el significado semántico?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2: Chunking dividiendo las oraciones\n",
    "\n",
    "#### Tarea #5 del Estudiante: \n",
    "\n",
    "Agrega código en la celda siguiente. Utiliza la biblioteca `spaCy` y específicamente la función `sents` para dividir el texto en trozos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Today was a fun day. I had lots of ice cream. I also met my best friend Sally and we played together at the new playground.\"\n",
    "\n",
    "# Agrega tu código aquí"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿Los resultados son mejores que el método en 4.1? La biblioteca `spaCy` ayuda a dividir el texto en oraciones individuales. Esto puede ser útil cuando intentas hacer resúmenes de texto. Puedes clasificar las oraciones individuales y usar los mejores resultados en el resumen."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3: Chunking con superposición de oraciones\n",
    "\n",
    "#### Tarea #6 del Estudiante: \n",
    "\n",
    "Ejecuta el código mostrado a continuación para ver otro ejemplo de chunking. Como verás, el significado semántico se mantiene. En otras palabras, se conserva el contexto entre las oraciones. Esto es especialmente importante cuando estás buscando datos para obtener resultados relevantes o cuando estás resumiendo un fragmento de texto. Es importante capturar las relaciones entre las oraciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"The sun was setting over the horizon, casting a warm glow over the landscape. Birds chirped in the trees, and a gentle breeze rustled the leaves. In the distance, a herd of deer grazed in a meadow. The air was filled with the sweet scent of blooming flowers. It was a peaceful and serene scene, perfect for a quiet evening stroll.\"\n",
    "doc = nlp(text)\n",
    "\n",
    "sentences = list(doc.sents)\n",
    "overlap = 1\n",
    "chunks =[]\n",
    "\n",
    "for i in range(len(sentences) - overlap):\n",
    "    chunk = sentences[i : i + overlap + 1]\n",
    "    chunks.append(chunk)\n",
    "\n",
    "for chunk in chunks:\n",
    "    print([sent.text for sent in chunk])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4: Chunking de forma recursiva usando LangChain\n",
    "\n",
    "#### Tarea #7 del Estudiante: \n",
    "\n",
    "Agrega los parámetros requeridos para `RecursiveCharacterSplitter` en la celda siguiente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_text = RecursiveCharacterTextSplitter(\n",
    "   # Agrega los parámetros aquí\n",
    ")\n",
    "docs = split_text.create_documents([clean_text])\n",
    "docs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Acabamos de realizar algunas fragmentaciones utilizando Langchain, un framework popular para crear aplicaciones utilizando modelos de lenguaje grandes. En los métodos anteriores, viste varios ejemplos de chunking. Langchain puede ayudar a hacer que el proceso de chunking sea más fácil con algunos de sus métodos. Estos métodos incluyen fragmentos de tamaño fijo, así como la fragmentación recursiva, que acabamos de ver.\n",
    "\n",
    "Por ejemplo, existe `CharacterTextSplitter` que dividirá el texto dado en un fragmento de tamaño fijo de un tamaño determinado y una superposición de caracteres determinada.\n",
    "\n",
    "`RecursiveCharacterTextSplitter` divide el texto en fragmentos más pequeños de manera iterativa. Nuevamente, puedes proporcionar el tamaño del fragmento y el recuento de superposición del fragmento."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La segmentación es una técnica importante por muchas razones. Ayuda a evitar el límite de tokens cuando se trabaja con grandes cantidades de datos y también optimiza la respuesta que recibimos del modelo. Encontrar la técnica de segmentación adecuada y el tamaño de fragmento es crucial para recibir respuestas relevantes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Criterios de Éxito\n",
    "\n",
    "Para completar este desafío con éxito:\n",
    "\n",
    "* Demuestra una comprensión de los tokens y cómo calcularlos.\n",
    "* Demuestra una comprensión de la segmentación (chunking) experimentando con diferentes técnicas.\n",
    "* Sé capaz de entender la importancia de encontrar la solución de segmentación adecuada según si se captura o no el significado semántico."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
